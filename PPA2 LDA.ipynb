{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.tokenize import word_tokenize #from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords') \n,
    "\n",
    "nltk.download('punkt') #for tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(text): \n",
    "    tokens = word_tokenize(text) \n",
    "    #tokens = word_tokenize(text.lower()) \n",
    "    return (\" \").join([word for word in tokens if word not in stopwords.words()]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does the Wikipedia package work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Madrid\"\n",
    "page1 = wikipedia.page(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Rome\"\n",
    "page2 = wikipedia.page(title) #An error what happened?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page2 = wikipedia.page(\"Roma\") #Is this better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page1.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page1.coordinates  # categories, content, coordinates, summary, sections, url,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page2.summary[0:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All together we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Florence\"\n",
    "page1 = wikipedia.page(title)\n",
    "text1 = page1.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wikipedia.page(\"Florence\")  accesses the webpage about Florence\n",
    "# .summary  access the text in that webpage\n",
    "\n",
    "wikipedia.page(\"Florence\").summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagetext = wikipedia.page(\"Florence\").summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = preprocessor(pagetext) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = preprocessor(wikipedia.page(\"London\").summary) \n",
    "\n",
    "text2 = preprocessor(wikipedia.page(\"Natural Language Processing\").summary) \n",
    "\n",
    "text3 = preprocessor(wikipedia.page(\"A Tale of Two Cities\").summary) \n",
    "\n",
    "text4 = preprocessor(wikipedia.page(\"Artificial intelligence\").summary) \n",
    "\n",
    "text5 = preprocessor(wikipedia.page(\"Berlin\").summary) \n",
    "\n",
    "text6 = preprocessor(wikipedia.page(\"For Whom the Bell Tolls\").summary) \n",
    "\n",
    "\n",
    "docs = [text1, text2, text3, text4, text5, text6] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiTitles = [\"London\", \"Natural Language Processing\", \"A Tale of Two Cities\",\n",
    "              \"Artificial intelligence\", \"Berlin\",\"For Whom the Bell Tolls\", \n",
    "              \"Roma\", \"Florence\", \"Madrid\"]\n",
    "\n",
    "\n",
    "\n",
    "docs = []\n",
    "\n",
    "for title in wikiTitles:\n",
    "    text1 = preprocessor(wikipedia.page(title).summary) \n",
    "    docs.append(text1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now to a little bit of LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countVectorizer = CountVectorizer(stop_words='english')\n",
    "termFrequency = countVectorizer.fit_transform(docs) # Bag of words\n",
    "featureNames = countVectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=3) \n",
    "lda.fit(termFrequency) \n",
    "\n",
    "\n",
    "for idx, topic in enumerate(lda.components_): \n",
    "    print (\"Topic \", idx, \" \".join(featureNames[i] for i in topic.argsort()[:-10 - 1:-1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewText = preprocessor(wikipedia.page(\"Paris\").summary)\n",
    "\n",
    "print (lda.transform(countVectorizer.transform([NewText])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now together\n",
    "Your homework give me a category and \n",
    "a few wikipedia articles in that category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category 1 - Animals\n",
    "\n",
    "cat1 = [\"Turtles\", \"Lizards\",\"Salamander\", \"Blue Jay\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category 2\n",
    "\n",
    "cat2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category 3\n",
    "\n",
    "cat3 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiTitles = cat1+cat2+cat3\n",
    "wikiTitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the wikipedia articles\n",
    "docs = []\n",
    "\n",
    "for title in wikiTitles:\n",
    "    text1 = preprocessor(wikipedia.page(title).summary) \n",
    "    docs.append(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the model\n",
    "countVectorizer = CountVectorizer(stop_words='english')\n",
    "termFrequency = countVectorizer.fit_transform(docs) # Bag of words\n",
    "featureNames = countVectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=3) \n",
    "lda.fit(termFrequency) \n",
    "\n",
    "\n",
    "for idx, topic in enumerate(lda.components_): \n",
    "    print (\"Topic \", idx, \" \".join(featureNames[i] for i in topic.argsort()[:-10 - 1:-1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewText = preprocessor(wikipedia.page(\"Dwight David Eisenhower\").summary)\n",
    "\n",
    "print (lda.transform(countVectorizer.transform([NewText])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A category 2  and category 3 I ran\n",
    "# cat2 = [\"Blue\", \"Magenta\", \"Cyan\", \"Yellow\"]\n",
    "# cat3 = [\"Ronald Reagan\",  \"Bill Clinton\",  \"Barack Obama\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiTitles = [\"Pittsburgh Steelers\", \"Terry Bradshaw\", \"Mike Tomlin\",\n",
    "               \"Neil Lomax\", \"AC/DC\",\"Library of Congress\",\n",
    "               \"Blues\",\n",
    "               \"World War II\", \"Luftwaffe\", \"Kamikaze\", \"Enola Gay\"]\n",
    "\n",
    "\n",
    "wikiArticles = []\n",
    "\n",
    "for title in wikiTitles:\n",
    "    text1 = preprocessor(wikipedia.page(title).summary) \n",
    "    wikiArticles.append(text1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countVectorizer = CountVectorizer(stop_words='english')\n",
    "termFrequency = countVectorizer.fit_transform(wikiArticles)\n",
    "featureNames = countVectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=3) \n",
    "lda.fit(termFrequency) \n",
    "  \n",
    "\n",
    "for idx, topic in enumerate(lda.components_): \n",
    "    print (\"Topic \", idx, \" \".join(featureNames[i] for i in topic.argsort()[:-10 - 1:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text7 = preprocessor(wikipedia.page(\"Paris\").summary)\n",
    "\n",
    "print(lda.transform(countVectorizer.transform([text7])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text7 = preprocessor(wikipedia.page(\"Dwight David Eisenhower\").summary)\n",
    "\n",
    "print(lda.transform(countVectorizer.transform([text7])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
